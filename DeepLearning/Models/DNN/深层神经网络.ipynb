{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 深层神经网络\n",
    "在一个深层神经网络中，涉及多个隐藏层。我们用上标 \\( L \\) 表示层数，其中 \\( L \\) 是网络的总层数，包括输入层和输出层。每一层 \\( l \\) 有 \\( n^{[l]} \\) 个神经元，其中 \\( n^{[0]} \\) 是输入特征的数量，\\( n^{[L]} \\) 是输出层的神经元数量。假设有 \\( m \\) 个样本。\n",
    "\n",
    "### 前向传播\n",
    "\n",
    "1. **初始化**\n",
    "   - 输入层: $\\( A^{[0]} = X \\) $ (大小为 $\\( n^{[0]} \\times m \\)$)\n",
    "\n",
    "2. **从第1层到第\\( L-1 \\)层（隐藏层）**\n",
    "   对于每一层 $\\( l = 1 \\)$ 到 $\\( L-1 \\)$：\n",
    "   - 权重矩阵: $\\( W^{[l]} \\)$ (大小为 $\\( n^{[l]} \\times n^{[l-1]} \\)$)\n",
    "   - 偏置向量: $\\( b^{[l]} \\)$ (大小为 $\\( n^{[l]} \\times 1 \\)$)\n",
    "   - 线性部分: $\\( Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]} \\)$ (大小为 $\\( n^{[l]} \\times m \\)$)\n",
    "   - 激活函数: $\\( A^{[l]} = g^{[l]}(Z^{[l]}) \\)$ (大小为 $\\( n^{[l]} \\times m \\)$)\n",
    "\n",
    "3. **输出层（第\\( L \\)层）**\n",
    "   - 权重矩阵: $\\( W^{[L]} \\)$ (大小为 $\\( n^{[L]} \\times n^{[L-1]} \\)$)\n",
    "   - 偏置向量: $\\( b^{[L]} \\)$ (大小为 $\\( n^{[L]} \\times 1 \\)$)\n",
    "   - 线性部分: $\\( Z^{[L]} = W^{[L]} A^{[L-1]} + b^{[L]} \\)$ (大小为 $\\( n^{[L]} \\times m \\)$)\n",
    "   - 激活函数: $\\( A^{[L]} = g^{[L]}(Z^{[L]}) \\)$ (大小为 $\\( n^{[L]} \\times m \\)$)\n",
    "\n",
    "4. **损失函数**\n",
    "   - $\\( J(A^{[L]}, Y) \\)$ (标量，大小为 1)\n",
    "\n",
    "### 反向传播\n",
    "\n",
    "1. **初始化梯度**\n",
    "   - 输出层梯度: $\\( dA^{[L]} = \\frac{\\partial J(A^{[L]}, Y)}{\\partial A^{[L]}} \\)$ (大小为 $\\( n^{[L]} \\times m \\)$)\n",
    "\n",
    "2. **从第\\( L \\)层到第2层**\n",
    "   对于每一层 $\\( l = L \\)$ 到 2：\n",
    "   - 激活函数的导数: $\\( dZ^{[l]} = dA^{[l]} \\odot g'^{[l]}(Z^{[l]}) \\)$ (大小为 $\\( n^{[l]} \\times m \\)$)\n",
    "   - 权重梯度: $\\( dW^{[l]} = \\frac{1}{m} dZ^{[l]} (A^{[l-1]})^T \\)$ (大小为 $\\( n^{[l]} \\times n^{[l-1]} \\)$)\n",
    "   - 偏置梯度: $\\( db^{[l]} = \\frac{1}{m} np.sum(dZ^{[l]}, axis = 1, keepdims = True) \\)$ (大小为 $\\( n^{[l]} \\times 1 \\)$)\n",
    "   - 上一层梯度: $\\( dA^{[l-1]} = (W^{[l]})^T dZ^{[l]} \\)$ (大小为 $\\( n^{[l-1]} \\times m \\)$)\n",
    "\n",
    "3. **第1层**\n",
    "   - 激活函数的导数: $\\( dZ^{[1]} = dA^{[1]} \\odot g'^{[1]}(Z^{[1]}) \\)$ (大小为 $\\( n^{[1]} \\times m \\)$)\n",
    "   - 权重梯度: $\\( dW^{[1]} = \\frac{1\n",
    "\n",
    "}{m} dZ^{[1]} (A^{[0]})^T \\)$ (大小为 $\\( n^{[1]} \\times n^{[0]} \\)$)\n",
    "   - 偏置梯度: $\\( db^{[1]} = \\frac{1}{m} np.sum(dZ^{[1]}, axis = 1, keepdims = True) \\)$ (大小为 $\\( n^{[1]} \\times 1 \\)$)\n",
    "\n",
    "### 参数更新\n",
    "\n",
    "对于每一层 $\\( l = 1 \\)$ 到 $\\( L \\)$：\n",
    "- $\\( W^{[l]} := W^{[l]} - \\alpha \\cdot dW^{[l]} \\)$\n",
    "- $\\( b^{[l]} := b^{[l]} - \\alpha \\cdot db^{[l]} \\)$\n",
    "\n",
    "这里，$\\( \\alpha \\)$ 是学习率。需要注意的是，由于 $\\( J(A^{[L]}, Y) \\)$ 的具体形式未知，因此 $\\( dA^{[L]} \\)$ 的具体计算依赖于损失函数的具体形式。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9990ebb64ff2ade0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-13T08:42:00.940506Z",
     "start_time": "2024-01-13T08:42:00.938981Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
