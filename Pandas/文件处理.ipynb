{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 读取文件\n",
    "\n",
    "`pd.read_csv(\"path/to/your/csv/file\", header = 0, names = [], index_col = None,`\n",
    "\n",
    "                `encoding = \"utf-8\", sep = \",\", dtype = {},`\n",
    "\n",
    "                `skiprows = [], nrows = [], usecols = [], na_values = [],`\n",
    "\n",
    "                `parse_dates = [], date_parser = lambda x: datetime.datetime.strptime(x, format = \"%Y-%m-%d %H:%M:%S\")`\n",
    "\n",
    "                `iterator = False, chunksize = None)`\n",
    "\n",
    "- 读取 csv 文件，默认第一行为列名，如果没有列名，可以通过 `names` 参数指定列名\n",
    "\n",
    "- 如果同时指定了 `header` 和 `names` ，则表中内容为 `header` 之后的所有行，但是表头的列名不再是 `header` ，而是由 `names` 覆盖\n",
    "\n",
    "- `index_col` 指定某一列为索引列\n",
    "\n",
    "- `encoding` 指定编码格式\n",
    "\n",
    "- `sep` 指定分隔符\n",
    "\n",
    "- `dtype` 指定每一列的数据类型\n",
    "\n",
    "- `skiprows` 指定跳过的行数, 可以是整数或者列表，也可以是 lambda 函数\n",
    "\n",
    "- `nrows` 指定读取的行数, 数据类型同上\n",
    "\n",
    "- `usecols` 指定读取的列数, 数据类型同上\n",
    "\n",
    "- `na_values` 指定哪些数据要更改为缺失值\n",
    "\n",
    "- `parse_dates` 指定哪些列需要转换为日期格式\n",
    "\n",
    "- `date_parser` 指定日期格式\n",
    "\n",
    "- `iterator` 用来分块读入大文件\n",
    "\n",
    "- `chunksize` 指定每次迭代的行数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "=========================================\n",
      "   1  5.1  3.5  1.4  0.2  Iris-setosa\n",
      "0  2  4.9  3.0  1.4  0.2  Iris-setosa\n",
      "1  3  4.7  3.2  1.3  0.2  Iris-setosa\n",
      "=========================================\n",
      "                a             b              c             d            e\n",
      "Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "1             5.1           3.5            1.4           0.2  Iris-setosa\n",
      "=========================================\n",
      "             Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "Species                                                                  \n",
      "Iris-setosa   1            5.1           3.5            1.4           0.2\n",
      "Iris-setosa   2            4.9           3.0            1.4           0.2\n",
      "=========================================\n",
      "     a    b    c    d            e\n",
      "2  4.9  3.0  1.4  0.2  Iris-setosa\n",
      "3  4.7  3.2  1.3  0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "iris = pd.read_csv(\"/Users/zhaohaonan/北大资料/Coding/MachineLearning/Datasets/Iris.csv\")\n",
    "print(iris.head(2))\n",
    "print(\"=========================================\")\n",
    "\n",
    "iris_1 = pd.read_csv(\n",
    "    \"/Users/zhaohaonan/北大资料/Coding/MachineLearning/Datasets/Iris.csv\", header=1\n",
    ")\n",
    "print(iris_1.head(2))\n",
    "print(\"=========================================\")\n",
    "\n",
    "iris_2 = pd.read_csv(\n",
    "    \"/Users/zhaohaonan/北大资料/Coding/MachineLearning/Datasets/Iris.csv\",\n",
    "    names=[\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    ")\n",
    "print(iris_2.head(2))\n",
    "print(\"=========================================\")\n",
    "\n",
    "iris_3 = pd.read_csv(\n",
    "    \"/Users/zhaohaonan/北大资料/Coding/MachineLearning/Datasets/Iris.csv\",\n",
    "    index_col=\"Species\",\n",
    ")\n",
    "print(iris_3.head(2))\n",
    "print(\"=========================================\")\n",
    "\n",
    "iris_4 = pd.read_csv(\n",
    "    \"/Users/zhaohaonan/北大资料/Coding/MachineLearning/Datasets/Iris.csv\",\n",
    "    header=1,\n",
    "    names=[\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    ")\n",
    "print(iris_4.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分块读取数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_chunk 数据类型： <class 'pandas.io.parsers.readers.TextFileReader'>\n",
      "===============================================================\n",
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "5   6            5.4           3.9            1.7           0.4  Iris-setosa\n",
      "6   7            4.6           3.4            1.4           0.3  Iris-setosa\n",
      "7   8            5.0           3.4            1.5           0.2  Iris-setosa\n",
      "8   9            4.4           2.9            1.4           0.2  Iris-setosa\n",
      "9  10            4.9           3.1            1.5           0.1  Iris-setosa\n",
      "===============================================================\n",
      "    Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "10  11            5.4           3.7            1.5           0.2  Iris-setosa\n",
      "11  12            4.8           3.4            1.6           0.2  Iris-setosa\n",
      "12  13            4.8           3.0            1.4           0.1  Iris-setosa\n",
      "13  14            4.3           3.0            1.1           0.1  Iris-setosa\n",
      "14  15            5.8           4.0            1.2           0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "iris_chunk = pd.read_csv(\n",
    "    \"/Users/zhaohaonan/北大资料/Coding/MachineLearning/Datasets/Iris.csv\",\n",
    "    iterator=True,\n",
    "    chunksize=10,\n",
    ")\n",
    "print(\"iris_chunk 数据类型：\", type(iris_chunk))\n",
    "print(\"===============================================================\")\n",
    "\n",
    "# 默认一组是 chunksize=10 个\n",
    "print(iris_chunk.get_chunk())\n",
    "print(\"===============================================================\")\n",
    "\n",
    "print(iris_chunk.get_chunk(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取时间序列相关文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Name  Class\n",
      "Birthday              \n",
      "07/09/2011    A      2\n",
      "09/12/2001    B      3\n",
      "09/11/1998    C      3\n",
      "09/06/2001    D      4\n",
      "04/08/1999    E      1\n",
      "=========================================\n",
      "转换日期格式\n",
      "           Name  Class\n",
      "Birthday              \n",
      "2011-07-09    A      2\n",
      "2001-09-12    B      3\n",
      "1998-09-11    C      3\n",
      "2001-09-06    D      4\n",
      "1999-04-08    E      1\n",
      "=========================================\n",
      "日期升序排序\n",
      "           Name  Class\n",
      "Birthday              \n",
      "1998-09-11    C      3\n",
      "1999-04-08    E      1\n",
      "2001-09-06    D      4\n",
      "2001-09-12    B      3\n",
      "2011-07-09    A      2\n",
      "=========================================\n",
      "日期索引\n",
      "           Name  Class\n",
      "Birthday              \n",
      "2001-09-06    D      4\n",
      "2001-09-12    B      3\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/Users/zhaohaonan/北大资料/Coding/MachineLearning/Datasets/birthday.csv\",\n",
    "    index_col=\"Birthday\",\n",
    ")\n",
    "print(df)\n",
    "print(\"=========================================\")\n",
    "\n",
    "# 将日期格式转换为 pandas 的日期格式\n",
    "print(\"转换日期格式\")\n",
    "df.index = pd.to_datetime(df.index)\n",
    "print(df)\n",
    "print(\"=========================================\")\n",
    "\n",
    "# 然后就可以直接对日期进行排序和索引了\n",
    "print(\"日期升序排序\")\n",
    "df.sort_index(axis=0, inplace=True)\n",
    "print(df)\n",
    "print(\"=========================================\")\n",
    "\n",
    "print(\"日期索引\")\n",
    "print(df.loc[\"2001-09\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 缺失值处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Gender  Salary\n",
      "A   NaN    Male  1000.0\n",
      "B  20.0  Female  2000.0\n",
      "C  30.0     NaN  3000.0\n",
      "D   NaN    Male     NaN\n"
     ]
    }
   ],
   "source": [
    "age = pd.Series([20, 30], index=[\"B\", \"C\"], dtype=np.int64)\n",
    "salary = pd.Series([1000, 2000, 3000], index=[\"A\", \"B\", \"C\"])\n",
    "gender = pd.Series([\"Male\", \"Female\", \"Male\"], index=[\"A\", \"B\", \"D\"])\n",
    "data = {\"Age\": age, \"Gender\": gender, \"Salary\": salary}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 查看缺失值\n",
    "\n",
    "- `df.isnull()` 查看缺失值\n",
    "- `df.isnull().any(axis=0/1)` 查看每列/行是否有缺失值\n",
    "- `df.isnull().sum()` 查看每列缺失值数量\n",
    "- `df.isnull().sum().sum()` 查看所有缺失值数量\n",
    "- `df.info()` 查看每列缺失值数量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age       2\n",
      "Gender    1\n",
      "Salary    1\n",
      "dtype: int64\n",
      "===========\n",
      "Age       True\n",
      "Gender    True\n",
      "Salary    True\n",
      "dtype: bool\n",
      "===========\n",
      "A     True\n",
      "B    False\n",
      "C     True\n",
      "D     True\n",
      "dtype: bool\n",
      "===========\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4 entries, A to D\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Age     2 non-null      float64\n",
      " 1   Gender  3 non-null      object \n",
      " 2   Salary  3 non-null      float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 128.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "print(\"===========\")\n",
    "print(df.isnull().any())\n",
    "print(\"===========\")\n",
    "print(df.isnull().any(axis=1))\n",
    "print(\"===========\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 删除缺失值\n",
    "\n",
    "`df.dropna(axis=0/1, how='any/all', thresh=None, subset=None, inplace=True)`\n",
    "\n",
    "- axis: 0-行操作（删除行），1-列操作（删除列）\n",
    "- how: any-只要有缺失值出现就删除，all-全部缺失值才删除\n",
    "- thresh: int-至少需要非 NaN 的数据个数\n",
    "- subset: list-指定列\n",
    "- inplace: bool-是否替换原数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Gender  Salary\n",
      "A   NaN    Male  1000.0\n",
      "B  20.0  Female  2000.0\n",
      "C  30.0     NaN  3000.0\n",
      "D   NaN    Male     NaN\n",
      "======================\n",
      "删除至少一个缺失值的行\n",
      "    Age  Gender  Salary\n",
      "B  20.0  Female  2000.0\n",
      "======================\n",
      "删除至少一个缺失值的列\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [A, B, C, D]\n",
      "======================\n",
      "删除所有值都缺失的行\n",
      "    Age  Gender  Salary\n",
      "A   NaN    Male  1000.0\n",
      "B  20.0  Female  2000.0\n",
      "C  30.0     NaN  3000.0\n",
      "D   NaN    Male     NaN\n",
      "======================\n",
      "删除所有值都缺失的列\n",
      "    Age  Gender  Salary\n",
      "A   NaN    Male  1000.0\n",
      "B  20.0  Female  2000.0\n",
      "C  30.0     NaN  3000.0\n",
      "D   NaN    Male     NaN\n",
      "======================\n",
      "删除指定列中缺失值的行\n",
      "    Age  Gender  Salary\n",
      "B  20.0  Female  2000.0\n",
      "C  30.0     NaN  3000.0\n",
      "======================\n",
      "指定最少非缺失值个数\n",
      "    Age  Gender  Salary\n",
      "A   NaN    Male  1000.0\n",
      "B  20.0  Female  2000.0\n",
      "C  30.0     NaN  3000.0\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "print(\"======================\")\n",
    "\n",
    "# 删除至少一个缺失值的行\n",
    "print(\"删除至少一个缺失值的行\")\n",
    "df1 = df.dropna(axis=0, how=\"any\")\n",
    "print(df1)\n",
    "print(\"======================\")\n",
    "\n",
    "# 删除至少一个缺失值的列\n",
    "print(\"删除至少一个缺失值的列\")\n",
    "df2 = df.dropna(axis=1, how=\"any\")\n",
    "print(df2)\n",
    "print(\"======================\")\n",
    "\n",
    "# 删除所有值都缺失的行\n",
    "print(\"删除所有值都缺失的行\")\n",
    "df3 = df.dropna(axis=0, how=\"all\")\n",
    "print(df3)\n",
    "print(\"======================\")\n",
    "\n",
    "# 删除所有值都缺失的列\n",
    "print(\"删除所有值都缺失的列\")\n",
    "df4 = df.dropna(axis=1, how=\"all\")\n",
    "print(df4)\n",
    "print(\"======================\")\n",
    "\n",
    "# 删除指定列中缺失值的行\n",
    "print(\"删除指定列中缺失值的行\")\n",
    "df5 = df.dropna(axis=0, how=\"any\", subset=[\"Age\", \"Salary\"])\n",
    "print(df5)\n",
    "print(\"======================\")\n",
    "\n",
    "# 指定最少非缺失值个数\n",
    "print(\"指定最少非缺失值个数\")\n",
    "df7 = df.dropna(axis=0, thresh=2)\n",
    "print(df7)\n",
    "print(\"======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 填充缺失值\n",
    "\n",
    "`df.fillna(value=None, axis=None, inplace=False, limit=None, downcast=None)`\n",
    "\n",
    "- value: 填充值\n",
    "- axis: 0-按行操作，1-按列操作\n",
    "- inplace: bool-是否替换原数据\n",
    "- limit: int-填充个数限制\n",
    "- downcast: dict-指定列的填充方式\n",
    "\n",
    "向前向后填充\n",
    "\n",
    "- `df.ffill(axis=0/1)`\n",
    "- `df.bfill(axis=0/1)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Gender  Salary\n",
      "A   NaN    Male  1000.0\n",
      "B  20.0  Female  2000.0\n",
      "C  30.0     NaN  3000.0\n",
      "D   NaN    Male     NaN\n",
      "======================\n",
      "向前填充\n",
      "    Age  Gender  Salary\n",
      "A   NaN    Male  1000.0\n",
      "B  20.0  Female  2000.0\n",
      "C  30.0  Female  3000.0\n",
      "D  30.0    Male  3000.0\n",
      "======================\n",
      "向后填充\n",
      "    Age  Gender  Salary\n",
      "A  Male    Male  1000.0\n",
      "B  20.0  Female  2000.0\n",
      "C  30.0  3000.0  3000.0\n",
      "D  Male    Male     NaN\n",
      "======================\n",
      "Age 列的均值填充\n",
      "    Age  Gender  Salary\n",
      "A  25.0    Male  1000.0\n",
      "B  20.0  Female  2000.0\n",
      "C  30.0     NaN  3000.0\n",
      "D  25.0    Male     NaN\n",
      "======================\n",
      "Salary 列的中位数填充\n",
      "    Age  Gender  Salary\n",
      "A   NaN    Male  1000.0\n",
      "B  20.0  Female  2000.0\n",
      "C  30.0     NaN  3000.0\n",
      "D   NaN    Male  2000.0\n",
      "======================\n",
      "Gender 列的众数填充\n",
      "    Age  Gender  Salary\n",
      "A   NaN    Male  1000.0\n",
      "B  20.0  Female  2000.0\n",
      "C  30.0    Male  3000.0\n",
      "D   NaN    Male     NaN\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "print(\"======================\")\n",
    "\n",
    "# 按列向前填充\n",
    "print(\"向前填充\")\n",
    "df8 = df.ffill(axis=0)\n",
    "print(df8)\n",
    "print(\"======================\")\n",
    "\n",
    "# 按行向后填充\n",
    "print(\"向后填充\")\n",
    "df9 = df.bfill(axis=1)\n",
    "print(df9)\n",
    "print(\"======================\")\n",
    "\n",
    "# Age 列的均值填充\n",
    "print(\"Age 列的均值填充\")\n",
    "df10 = df.fillna(value={\"Age\": df[\"Age\"].mean()})\n",
    "print(df10)\n",
    "print(\"======================\")\n",
    "\n",
    "# Salary 列的中位数填充\n",
    "print(\"Salary 列的中位数填充\")\n",
    "df11 = df.fillna(value={\"Salary\": df[\"Salary\"].median()})\n",
    "print(df11)\n",
    "print(\"======================\")\n",
    "\n",
    "# Gender 列的众数填充\n",
    "print(\"Gender 列的众数填充\")\n",
    "df12 = df.fillna(value={\"Gender\": df[\"Gender\"].mode()[0]})\n",
    "print(df12)\n",
    "print(\"======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 分组操作\n",
    "\n",
    "随机生成十个样本数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID company  salary  age\n",
      "0  2000012510       A       6   41\n",
      "1  2000012511       A      27   40\n",
      "2  2000012512       C      19   40\n",
      "3  2000012513       B      21   16\n",
      "4  2000012514       A      18   32\n",
      "5  2000012515       C      25   44\n",
      "6  2000012516       C      35   15\n",
      "7  2000012517       B       5   19\n",
      "8  2000012518       C      36   48\n",
      "9  2000012519       C      24   43\n"
     ]
    }
   ],
   "source": [
    "company_name = np.array([\"A\", \"B\", \"C\"])\n",
    "\n",
    "# 生成 dataframe\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"ID\": np.arange(2000012510, 2000012520),\n",
    "        \"company\": np.random.choice(company_name, size=10),\n",
    "        \"salary\": np.random.randint(5, 50, size=10),\n",
    "        \"age\": np.random.randint(15, 50, size=10),\n",
    "    }\n",
    ")\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Groupby 分组\n",
    "\n",
    "`df.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)`\n",
    "\n",
    "- by: 指定分组依据，可以是列名、字典、Series、函数\n",
    "\n",
    "- axis: 0-按行分组，1-按列分组\n",
    "\n",
    "- level: 指定索引层级\n",
    "\n",
    "- as_index: bool-是否以分组依据作为索引\n",
    "\n",
    "- sort: bool-是否对分组依据进行排序\n",
    "\n",
    "- group_keys: bool-是否显示分组依据\n",
    "\n",
    "- squeeze: bool-是否压缩为 Series\n",
    "\n",
    "- observed: bool-是否按照观察到的数据进行分组\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n",
      "[('A',            ID company  salary  age\n",
      "0  2000012510       A       6   41\n",
      "1  2000012511       A      27   40\n",
      "4  2000012514       A      18   32), ('B',            ID company  salary  age\n",
      "3  2000012513       B      21   16\n",
      "7  2000012517       B       5   19), ('C',            ID company  salary  age\n",
      "2  2000012512       C      19   40\n",
      "5  2000012515       C      25   44\n",
      "6  2000012516       C      35   15\n",
      "8  2000012518       C      36   48\n",
      "9  2000012519       C      24   43)]\n",
      "======================\n",
      "{'A': [0, 1, 4], 'B': [3, 7], 'C': [2, 5, 6, 8, 9]}\n"
     ]
    }
   ],
   "source": [
    "grouped = data.groupby(by=\"company\")\n",
    "print(type(grouped))\n",
    "print(list(grouped))\n",
    "print(\"======================\")\n",
    "print(grouped.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Aggregation 聚合\n",
    "\n",
    "`DataFrameGroupBy.agg({col_name:method})`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不同公司的平均状况\n",
      "         salary        age\n",
      "company                   \n",
      "A          17.0  37.666667\n",
      "B          13.0  17.500000\n",
      "C          27.8  38.000000\n",
      "======================\n",
      "平均薪资和年龄中位数\n",
      "         salary_mean  age_median\n",
      "company                         \n",
      "A               17.0        40.0\n",
      "B               13.0        17.5\n",
      "C               27.8        43.0\n"
     ]
    }
   ],
   "source": [
    "# 求不同公司的平均薪资、平均年龄\n",
    "print(\"不同公司的平均状况\")\n",
    "print(grouped[[\"salary\", \"age\"]].mean())\n",
    "print(\"======================\")\n",
    "\n",
    "# 平均薪资和年龄中位数\n",
    "print(\"平均薪资和年龄中位数\")\n",
    "result = grouped.agg({\"salary\": \"mean\", \"age\": \"median\"})\n",
    "result.columns = [\"salary_mean\", \"age_median\"]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Transformation 变换\n",
    "\n",
    "应用场景：在原数据表中添加一列，该列的值是原数据表中某一列的聚合结果\n",
    "\n",
    "e.g. 在原数据表中添加一列，该列的值是原数据表中 salary 的均值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 17.0, 'B': 13.0, 'C': 27.8}\n",
      "======================\n",
      "           ID company  salary  age  salary_mean\n",
      "0  2000012510       A       6   41         17.0\n",
      "1  2000012511       A      27   40         17.0\n",
      "2  2000012512       C      19   40         27.8\n",
      "3  2000012513       B      21   16         13.0\n",
      "4  2000012514       A      18   32         17.0\n",
      "5  2000012515       C      25   44         27.8\n",
      "6  2000012516       C      35   15         27.8\n",
      "7  2000012517       B       5   19         13.0\n",
      "8  2000012518       C      36   48         27.8\n",
      "9  2000012519       C      24   43         27.8\n"
     ]
    }
   ],
   "source": [
    "# 不使用 transform 的方法\n",
    "salary_mean = grouped[\"salary\"].mean()\n",
    "company2salary = salary_mean.to_dict()\n",
    "print(company2salary)\n",
    "print(\"======================\")\n",
    "\n",
    "data[\"salary_mean\"] = data[\"company\"].map(company2salary)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID company  salary  age  salary_mean\n",
      "0  2000012510       A       6   41         17.0\n",
      "1  2000012511       A      27   40         17.0\n",
      "2  2000012512       C      19   40         27.8\n",
      "3  2000012513       B      21   16         13.0\n",
      "4  2000012514       A      18   32         17.0\n",
      "5  2000012515       C      25   44         27.8\n",
      "6  2000012516       C      35   15         27.8\n",
      "7  2000012517       B       5   19         13.0\n",
      "8  2000012518       C      36   48         27.8\n",
      "9  2000012519       C      24   43         27.8\n"
     ]
    }
   ],
   "source": [
    "# 使用 transform 的方法\n",
    "data_copy = data.copy()\n",
    "data_copy[\"salary_mean\"] = grouped[\"salary\"].transform(\"mean\")\n",
    "print(data_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Apply 应用\n",
    "\n",
    "自行编写函数，函数的参数应该是分完组以后的每个组的 dataframe ，对分组后的数据进行操作\n",
    "\n",
    "apply() 调用自定义函数的时候，一定不要写()\n",
    "\n",
    "e.g. 要获取每个公司年龄最大的员工的信息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "年龄最大的员工\n",
      "                   ID company  salary  age  salary_mean\n",
      "company                                                \n",
      "A       0  2000012510       A       6   41         17.0\n",
      "B       7  2000012517       B       5   19         13.0\n",
      "C       8  2000012518       C      36   48         27.8\n"
     ]
    }
   ],
   "source": [
    "def get_oldest_staff(df):\n",
    "    return df.loc[df[\"age\"] == df[\"age\"].max()]\n",
    "\n",
    "\n",
    "print(\"年龄最大的员工\")\n",
    "print(grouped.apply(get_oldest_staff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 数据合并\n",
    "\n",
    "`pd.merge(left, right, how='inner/outer/left/right', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=True, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)`\n",
    "\n",
    "- left: 左表\n",
    "\n",
    "- right: 右表\n",
    "\n",
    "- how: inner-内连接，outer-外连接，left-左连接，right-右连接\n",
    "\n",
    "- on: 指定连接的列名，必须同时存在于左右两表中\n",
    "\n",
    "- left_on: 指定左表连接的列名\n",
    "\n",
    "- right_on: 指定右表连接的列名\n",
    "\n",
    "- left_index: bool-是否以左表的索引作为连接键\n",
    "\n",
    "- right_index: bool-是否以右表的索引作为连接键\n",
    "\n",
    "- sort: bool-是否对连接后的数据进行排序\n",
    "\n",
    "- suffixes: list-指定重叠列名的后缀\n",
    "\n",
    "- copy: bool-是否复制数据\n",
    "\n",
    "- indicator: bool-是否添加特殊列，用于指示该行数据来自哪个表\n",
    "\n",
    "- validate: str-检查连接类型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户年龄\n",
      "  user_id  age\n",
      "0       a   47\n",
      "1       b   23\n",
      "2       c   18\n",
      "3       d   37\n",
      "======================\n",
      "用户消费\n",
      "  user_id  consume\n",
      "0       a      100\n",
      "1       c      200\n",
      "2       e      300\n",
      "3       a      400\n"
     ]
    }
   ],
   "source": [
    "# 用户年龄\n",
    "user_age = pd.DataFrame(\n",
    "    {\n",
    "        \"user_id\": [\"a\", \"b\", \"c\", \"d\"],\n",
    "        \"age\": np.random.randint(15, 50, size=4),\n",
    "    }\n",
    ")\n",
    "print(\"用户年龄\")\n",
    "print(user_age)\n",
    "print(\"======================\")\n",
    "\n",
    "# 用户消费\n",
    "user_consume = pd.DataFrame(\n",
    "    {\"user_id\": [\"a\", \"c\", \"e\", \"a\"], \"consume\": [100, 200, 300, 400]}\n",
    ")\n",
    "print(\"用户消费\")\n",
    "print(user_consume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内连接\n",
      "  user_id  age  consume\n",
      "0       a   47      100\n",
      "1       a   47      400\n",
      "2       c   18      200\n",
      "======================\n",
      "外连接\n",
      "  user_id   age  consume\n",
      "0       a  47.0    100.0\n",
      "1       a  47.0    400.0\n",
      "2       b  23.0      NaN\n",
      "3       c  18.0    200.0\n",
      "4       d  37.0      NaN\n",
      "5       e   NaN    300.0\n",
      "======================\n",
      "左连接\n",
      "  user_id  age  consume\n",
      "0       a   47    100.0\n",
      "1       a   47    400.0\n",
      "2       b   23      NaN\n",
      "3       c   18    200.0\n",
      "4       d   37      NaN\n",
      "======================\n",
      "右连接\n",
      "  user_id   age  consume\n",
      "0       a  47.0      100\n",
      "1       a  47.0      400\n",
      "2       c  18.0      200\n",
      "3       e   NaN      300\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "# 连接这两个表的键是 \"user_id\"\n",
    "\n",
    "\n",
    "# inner 内连接，取交集\n",
    "print(\"内连接\")\n",
    "new_df = pd.merge(user_age, user_consume, on=\"user_id\", how=\"inner\")\n",
    "print(new_df)\n",
    "print(\"======================\")\n",
    "\n",
    "\n",
    "# outer 外连接，取并集\n",
    "print(\"外连接\")\n",
    "new_df = pd.merge(user_age, user_consume, on=\"user_id\", how=\"outer\")\n",
    "print(new_df)\n",
    "print(\"======================\")\n",
    "\n",
    "\n",
    "# left 左连接，以左边的表为基准\n",
    "print(\"左连接\")\n",
    "new_df = pd.merge(user_age, user_consume, on=\"user_id\", how=\"left\")\n",
    "print(new_df)\n",
    "print(\"======================\")\n",
    "\n",
    "\n",
    "# right 右连接，以右边的表为基准\n",
    "print(\"右连接\")\n",
    "new_df = pd.merge(user_age, user_consume, on=\"user_id\", how=\"right\",sort=True)\n",
    "print(new_df)\n",
    "print(\"======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 数据去重\n",
    "`df.drop_duplicates(subset=None, keep='first/last', inplace=False, ignore_index=False)`\n",
    "- subset: 指定去重的列名\n",
    "\n",
    "- keep: first-保留第一次出现的重复数据，last-保留最后一次出现的重复数据\n",
    "\n",
    "- inplace: bool-是否替换原数据\n",
    "\n",
    "- ignore_index: bool-是否重置索引\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
